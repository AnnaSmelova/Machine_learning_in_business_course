{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outside-leisure",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "1. Для нашего пайплайна (Case1) поэкспериментировать с разными моделями: 1 - бустинг, 2 - логистическая регрессия (не забудьте здесь добавить в cont_transformer стандартизацию - нормирование вещественных признаков)\n",
    "2. Отобрать лучшую модель по метрикам (кстати, какая по вашему мнению здесь наиболее подходящая DS-метрика)\n",
    "3. Для отобранной модели (на отложенной выборке) сделать оценку экономической эффективности при тех же вводных, как в вопросе 2 (1 доллар на привлечение, 2 доллара - с каждого правильно классифицированного (True Positive) удержанного). (подсказка) нужно посчитать FP/TP/FN/TN для выбранного оптимального порога вероятности и посчитать выручку и траты.\n",
    "4. (опционально) Провести подбор гиперпараметров лучшей модели по итогам 2-3\n",
    "5. (опционально) Еще раз провести оценку экономической эффективности\n",
    "### Ссылки\n",
    "http://hyperopt.github.io/hyperopt/ <br>\n",
    "https://arxiv.org/pdf/1907.03947.pdf <br>\n",
    "https://arxiv.org/pdf/1802.02301.pdf <br>\n",
    "https://arxiv.org/list/stat.ML/recent <br>\n",
    "https://scikit-learn.org/stable/modules/grid_search.html <br>\n",
    "https://scikit-learn.org/stable/modules/compose.html <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "qualified-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "buried-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-injury",
   "metadata": {},
   "source": [
    "1. Для нашего пайплайна (Case1) поэкспериментировать с разными моделями: 1 - бустинг, 2 - логистическая регрессия (не забудьте здесь добавить в cont_transformer стандартизацию - нормирование вещественных признаков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "celtic-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"churn_data.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "killing-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df['Exited'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-liverpool",
   "metadata": {},
   "source": [
    "- Категориальные признаки закодируем с помощью OneHotEncoding\n",
    "- Вещественные масштабируем с помощью StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eleven-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#соберем наш простой pipeline, но нам понадобится написать класс для выбора нужного поля\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in self.columns:\n",
    "            if col_ not in test_columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confidential-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим списки признаков\n",
    "categorical_columns = ['Geography', 'Gender', 'Tenure', 'HasCrCard', 'IsActiveMember']\n",
    "continuous_columns = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transformers = list()\n",
    "\n",
    "for cat_col in categorical_columns:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', FeatureSelector(column=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    final_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for cont_col in continuous_columns:\n",
    "    cont_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    final_transformers.append((cont_col, cont_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "massive-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединим все это в единый пайплайн\n",
    "feats = FeatureUnion(final_transformers)\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "established-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results = pd.DataFrame()\n",
    "models_results['model'] = []\n",
    "models_results['Precision'] = []\n",
    "models_results['Recall'] = []\n",
    "models_results['F-Score'] = []\n",
    "models_results['ROC_AUC'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-musical",
   "metadata": {},
   "source": [
    "Бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "radio-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_1 = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', xgb.XGBClassifier(random_state = 42, use_label_encoder=False, objective='binary:logistic', eval_metric='logloss')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sustainable-omaha",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('Geography',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Geography')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Geography'))])),\n",
       "                                                ('Gender',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Gender')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Gender'))])),\n",
       "                                                ('Tenure',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Tenu...\n",
       "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               use_label_encoder=False, validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучим наш пайплайн\n",
    "pipeline_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interesting-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47611395, 0.23087966, 0.07372608, 0.03141731, 0.02561874,\n",
       "       0.9679959 , 0.06951059, 0.2885457 , 0.11367497, 0.4902508 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds_1 = pipeline_1.predict_proba(X_test)[:, 1]\n",
    "preds_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "iraqi-answer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.373318, F-Score=0.626, Precision=0.619, Recall=0.633, ROC_AUC=0.861\n"
     ]
    }
   ],
   "source": [
    "precision_1, recall_1, thresholds_1 = precision_recall_curve(y_test, preds_1)\n",
    "\n",
    "fscore_1 = (2 * precision_1 * recall_1) / (precision_1 + recall_1)\n",
    "# locate the index of the largest f score\n",
    "ix_1 = np.argmax(fscore_1)\n",
    "roc_auc_1 = roc_auc_score(y_test, preds_1)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f, ROC_AUC=%.3f' % (thresholds_1[ix_1], \n",
    "                                                                        fscore_1[ix_1],\n",
    "                                                                        precision_1[ix_1],\n",
    "                                                                        recall_1[ix_1],\n",
    "                                                                        roc_auc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "waiting-sussex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.632613</td>\n",
       "      <td>0.62585</td>\n",
       "      <td>0.860921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  Precision    Recall  F-Score   ROC_AUC\n",
       "0  XGBClassifier   0.619231  0.632613  0.62585  0.860921"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = models_results.append({'model': 'XGBClassifier', \n",
    "                'Precision': precision_1[ix_1],\n",
    "                'Recall': recall_1[ix_1],\n",
    "                'F-Score': fscore_1[ix_1],\n",
    "                'ROC_AUC': roc_auc_1},\n",
    "                ignore_index=True)\n",
    "models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-cabin",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "intense-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_2 = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LogisticRegression(random_state = 42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abroad-nutrition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('Geography',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Geography')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Geography'))])),\n",
       "                                                ('Gender',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Gender')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Gender'))])),\n",
       "                                                ('Tenure',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Tenu...\n",
       "                                                                  NumberSelector(key='Balance')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('NumOfProducts',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='NumOfProducts')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('EstimatedSalary',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='EstimatedSalary')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())]))])),\n",
       "                ('classifier', LogisticRegression(random_state=42))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучим наш пайплайн\n",
    "pipeline_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adjusted-amount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22805865, 0.3350657 , 0.15347886, 0.12466446, 0.15507743,\n",
       "       0.6431308 , 0.06214346, 0.077948  , 0.36717132, 0.76751542])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds_2 = pipeline_2.predict_proba(X_test)[:, 1]\n",
    "preds_2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "polish-municipality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.289522, F-Score=0.510, Precision=0.462, Recall=0.568, ROC_AUC=0.772\n"
     ]
    }
   ],
   "source": [
    "precision_2, recall_2, thresholds_2 = precision_recall_curve(y_test, preds_2)\n",
    "\n",
    "fscore_2 = (2 * precision_2 * recall_2) / (precision_2 + recall_2)\n",
    "# locate the index of the largest f score\n",
    "ix_2 = np.argmax(fscore_2)\n",
    "roc_auc_2 = roc_auc_score(y_test, preds_2)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f, ROC_AUC=%.3f' % (thresholds_2[ix_2], \n",
    "                                                                        fscore_2[ix_2],\n",
    "                                                                        precision_2[ix_2],\n",
    "                                                                        recall_2[ix_2],\n",
    "                                                                        roc_auc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "statistical-thesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.632613</td>\n",
       "      <td>0.62585</td>\n",
       "      <td>0.860921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.567780</td>\n",
       "      <td>0.50970</td>\n",
       "      <td>0.772077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Precision    Recall  F-Score   ROC_AUC\n",
       "0       XGBClassifier   0.619231  0.632613  0.62585  0.860921\n",
       "1  LogisticRegression   0.462400  0.567780  0.50970  0.772077"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = models_results.append({'model': 'LogisticRegression', \n",
    "                'Precision': precision_2[ix_2],\n",
    "                'Recall': recall_2[ix_2],\n",
    "                'F-Score': fscore_2[ix_2],\n",
    "                'ROC_AUC': roc_auc_2},\n",
    "                ignore_index=True)\n",
    "models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-friendship",
   "metadata": {},
   "source": [
    "Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "finnish-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_3 = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', RandomForestClassifier(random_state = 42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "shaped-image",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('Geography',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Geography')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Geography'))])),\n",
       "                                                ('Gender',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Gender')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Gender'))])),\n",
       "                                                ('Tenure',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Tenu...\n",
       "                                                                  NumberSelector(key='Balance')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('NumOfProducts',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='NumOfProducts')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('EstimatedSalary',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='EstimatedSalary')),\n",
       "                                                                 ('standard',\n",
       "                                                                  StandardScaler())]))])),\n",
       "                ('classifier', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучим наш пайплайн\n",
    "pipeline_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "married-region",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37, 0.26, 0.17, 0.02, 0.02, 0.67, 0.04, 0.12, 0.15, 0.75])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds_3 = pipeline_3.predict_proba(X_test)[:, 1]\n",
    "preds_3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "political-fitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.380000, F-Score=0.641, Precision=0.654, Recall=0.629, ROC_AUC=0.864\n"
     ]
    }
   ],
   "source": [
    "precision_3, recall_3, thresholds_3 = precision_recall_curve(y_test, preds_3)\n",
    "\n",
    "fscore_3 = (2 * precision_3 * recall_3) / (precision_3 + recall_3)\n",
    "# locate the index of the largest f score\n",
    "ix_3 = np.argmax(fscore_3)\n",
    "roc_auc_3 = roc_auc_score(y_test, preds_3)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f, ROC_AUC=%.3f' % (thresholds_3[ix_3], \n",
    "                                                                        fscore_3[ix_3],\n",
    "                                                                        precision_3[ix_3],\n",
    "                                                                        recall_3[ix_3],\n",
    "                                                                        roc_auc_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "labeled-lodging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.632613</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.860921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.567780</td>\n",
       "      <td>0.509700</td>\n",
       "      <td>0.772077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.654397</td>\n",
       "      <td>0.628684</td>\n",
       "      <td>0.641283</td>\n",
       "      <td>0.863699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  Precision    Recall   F-Score   ROC_AUC\n",
       "0           XGBClassifier   0.619231  0.632613  0.625850  0.860921\n",
       "1      LogisticRegression   0.462400  0.567780  0.509700  0.772077\n",
       "2  RandomForestClassifier   0.654397  0.628684  0.641283  0.863699"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = models_results.append({'model': 'RandomForestClassifier', \n",
    "                'Precision': precision_3[ix_3],\n",
    "                'Recall': recall_3[ix_3],\n",
    "                'F-Score': fscore_3[ix_3],\n",
    "                'ROC_AUC': roc_auc_3},\n",
    "                ignore_index=True)\n",
    "models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-stable",
   "metadata": {},
   "source": [
    "2. Отобрать лучшую модель по метрикам (кстати, какая по вашему мнению здесь наиболее подходящая DS-метрика)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-venue",
   "metadata": {},
   "source": [
    "Наверное, f-мера подходит больше всех: нам нужно найти баланс между точностью предсказания(т.е. precision) и охватом(т.е. recall), так как нам неинтересно удерживать тех, кто и так не уйдет, но и упускать большую долю тех, кто точно уйдет тоже не хочется. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "subsequent-hygiene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.654397</td>\n",
       "      <td>0.628684</td>\n",
       "      <td>0.641283</td>\n",
       "      <td>0.863699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.632613</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.860921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.567780</td>\n",
       "      <td>0.509700</td>\n",
       "      <td>0.772077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  Precision    Recall   F-Score   ROC_AUC\n",
       "2  RandomForestClassifier   0.654397  0.628684  0.641283  0.863699\n",
       "0           XGBClassifier   0.619231  0.632613  0.625850  0.860921\n",
       "1      LogisticRegression   0.462400  0.567780  0.509700  0.772077"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results.sort_values(['F-Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-reynolds",
   "metadata": {},
   "source": [
    "Лучшим оказался случайный лес, но его мы разбирали на вебинаре, а из домашних моделей лучшая - бустинг."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-tracker",
   "metadata": {},
   "source": [
    "3. Для отобранной модели (на отложенной выборке) сделать оценку экономической эффективности при тех же вводных, как в вопросе 2 (1 доллар на привлечение, 2 доллара - с каждого правильно классифицированного (True Positive) удержанного). (подсказка) нужно посчитать FP/TP/FN/TN для выбранного оптимального порога вероятности и посчитать выручку и траты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "armed-eligibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1793,  198],\n",
       "       [ 188,  321]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, preds_1>thresholds_1[ix_1])\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "recreational-looking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 1793 - думаем уйдут -> уйдут\n",
      "FP = 198 - думаем уйдут -> не уйдут\n",
      "FN = 188 - думаем не уйдут -> уйдут\n",
      "TN = 321 - думаем не уйдут -> не уйдут\n"
     ]
    }
   ],
   "source": [
    "print(f'TP = {cnf_matrix[0][0]} - думаем уйдут -> уйдут')\n",
    "print(f'FP = {cnf_matrix[0][1]} - думаем уйдут -> не уйдут')\n",
    "print(f'FN = {cnf_matrix[1][0]} - думаем не уйдут -> уйдут')\n",
    "print(f'TN = {cnf_matrix[1][1]} - думаем не уйдут -> не уйдут')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-consensus",
   "metadata": {},
   "source": [
    "С удержанием:<br>\n",
    "Прибыль принесут только TP: потратим на удержание - получим доход. TP: $-1793*1 + 1793*2$<br>\n",
    "FP: потратим на удержание, доход получим. FP: $-198*1 + 198*2$<br>\n",
    "FN: не потратим на удержание, но потеряем доход с них. FN: $-188*2$<br>\n",
    "TN: не потратим на удержание, не потеряем доход: TN: $321*2$<br><br>\n",
    "Без удержания:<br>\n",
    "TP и FN уйдут и мы потеряем прибыль от них, останется только прибыль от FP и TN: $-2*1793 - 2*188 + 2*198 + 2*321$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dynamic-ranch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прибыль с удержанием: 2257\n",
      "Прибыль без удержания: -2924\n"
     ]
    }
   ],
   "source": [
    "res_with_model = 1793 + 198 - 2*188 + 321*2\n",
    "res_without_model = -2*1793 - 2*188 + 2*198 + 2*321\n",
    "print(f'Прибыль с удержанием: {res_with_model}')\n",
    "print(f'Прибыль без удержания: {res_without_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-gateway",
   "metadata": {},
   "source": [
    "Получилось, что наша модель потенциально экономически целесообразна."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-position",
   "metadata": {},
   "source": [
    "4. (опционально) Провести подбор гиперпараметров лучшей модели по итогам 2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acting-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'classifier__learning_rate':[0.01, 0.3],\n",
    "        'classifier__gamma':[0, 0.5],\n",
    "        'classifier__max_depth':[None, 3, 10],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "patent-immunology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 49s, sys: 3.02 s, total: 4min 52s\n",
      "Wall time: 1min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__gamma': 0.5,\n",
       " 'classifier__learning_rate': 0.3,\n",
       " 'classifier__max_depth': 3}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid = GridSearchCV(pipeline_1,\n",
    "                    param_grid=params,\n",
    "                    cv=6,\n",
    "                    refit=False)\n",
    "\n",
    "search = grid.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "matched-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_4 = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', xgb.XGBClassifier(random_state = 42, \n",
    "                                     use_label_encoder=False, \n",
    "                                     objective='binary:logistic', \n",
    "                                     eval_metric='logloss',\n",
    "                                     gamma=0.5, \n",
    "                                     learning_rate=0.3, \n",
    "                                     max_depth=3)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "separate-briefing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('Geography',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Geography')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Geography'))])),\n",
       "                                                ('Gender',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Gender')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEEncoder(key='Gender'))])),\n",
       "                                                ('Tenure',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Tenu...\n",
       "                               gamma=0.5, gpu_id=-1, importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.3,\n",
       "                               max_delta_step=0, max_depth=3,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               use_label_encoder=False, validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#обучим наш пайплайн\n",
    "pipeline_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "lightweight-ordinary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23872866, 0.18331882, 0.19888023, 0.07336348, 0.01720506,\n",
       "       0.8186907 , 0.03651758, 0.07182581, 0.21028003, 0.7489    ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#наши прогнозы для тестовой выборки\n",
    "preds_4 = pipeline_4.predict_proba(X_test)[:, 1]\n",
    "preds_4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "funded-arbitration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.332742, F-Score=0.646, Precision=0.632, Recall=0.660, ROC_AUC=0.874\n"
     ]
    }
   ],
   "source": [
    "precision_4, recall_4, thresholds_4 = precision_recall_curve(y_test, preds_4)\n",
    "\n",
    "fscore_4 = (2 * precision_4 * recall_4) / (precision_4 + recall_4)\n",
    "# locate the index of the largest f score\n",
    "ix_4 = np.argmax(fscore_4)\n",
    "roc_auc_4 = roc_auc_score(y_test, preds_4)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f, ROC_AUC=%.3f' % (thresholds_4[ix_4], \n",
    "                                                                        fscore_4[ix_4],\n",
    "                                                                        precision_4[ix_4],\n",
    "                                                                        recall_4[ix_4],\n",
    "                                                                        roc_auc_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "missing-crowd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.632613</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.860921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.567780</td>\n",
       "      <td>0.509700</td>\n",
       "      <td>0.772077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.654397</td>\n",
       "      <td>0.628684</td>\n",
       "      <td>0.641283</td>\n",
       "      <td>0.863699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBClassifier_best</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.660118</td>\n",
       "      <td>0.645533</td>\n",
       "      <td>0.874029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  Precision    Recall   F-Score   ROC_AUC\n",
       "0           XGBClassifier   0.619231  0.632613  0.625850  0.860921\n",
       "1      LogisticRegression   0.462400  0.567780  0.509700  0.772077\n",
       "2  RandomForestClassifier   0.654397  0.628684  0.641283  0.863699\n",
       "3      XGBClassifier_best   0.631579  0.660118  0.645533  0.874029"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = models_results.append({'model': 'XGBClassifier_best', \n",
    "                'Precision': precision_4[ix_4],\n",
    "                'Recall': recall_4[ix_4],\n",
    "                'F-Score': fscore_4[ix_4],\n",
    "                'ROC_AUC': roc_auc_4},\n",
    "                ignore_index=True)\n",
    "models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-genre",
   "metadata": {},
   "source": [
    "5. (опционально) Еще раз провести оценку экономической эффективности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "governing-natural",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1795,  196],\n",
       "       [ 174,  335]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, preds_4>thresholds_4[ix_4])\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "exotic-sunday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 1795 - думаем уйдут -> уйдут\n",
      "FP = 196 - думаем уйдут -> не уйдут\n",
      "FN = 174 - думаем не уйдут -> уйдут\n",
      "TN = 335 - думаем не уйдут -> не уйдут\n"
     ]
    }
   ],
   "source": [
    "print(f'TP = {cnf_matrix[0][0]} - думаем уйдут -> уйдут')\n",
    "print(f'FP = {cnf_matrix[0][1]} - думаем уйдут -> не уйдут')\n",
    "print(f'FN = {cnf_matrix[1][0]} - думаем не уйдут -> уйдут')\n",
    "print(f'TN = {cnf_matrix[1][1]} - думаем не уйдут -> не уйдут')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-warrant",
   "metadata": {},
   "source": [
    "С удержанием:<br>\n",
    "Прибыль принесут только TP: потратим на удержание - получим доход. TP: $-1795*1 + 1795*2$<br>\n",
    "FP: потратим на удержание, доход получим. FP: $-196*1 + 196*2$<br>\n",
    "FN: не потратим на удержание, но потеряем доход с них. FN: $-174*2$<br>\n",
    "TN: не потратим на удержание, не потеряем доход: TN: $335*2$<br><br>\n",
    "Без удержания:<br>\n",
    "TP и FN уйдут и мы потеряем прибыль от них, останется только прибыль от FP и TN: $-2*1795 - 2*174 + 2*196 + 2*335$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sticky-reaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прибыль с удержанием: 2313\n",
      "Прибыль без удержания: -2876\n"
     ]
    }
   ],
   "source": [
    "res_with_model = 1795 + 196 - 2*174 + 335*2\n",
    "res_without_model = -2*1795 - 2*174 + 2*196 + 2*335\n",
    "print(f'Прибыль с удержанием: {res_with_model}')\n",
    "print(f'Прибыль без удержания: {res_without_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-accessory",
   "metadata": {},
   "source": [
    "Было:<br>\n",
    "Прибыль с удержанием: 2257<br>\n",
    "Прибыль без удержания: -2924"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-ending",
   "metadata": {},
   "source": [
    "Выгода от модели немного увеличилась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-venture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
